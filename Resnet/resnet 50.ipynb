{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc4e7ec-3233-4b8a-8c68-618c36e753b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, roc_curve, auc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset, SubsetRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.models as models\n",
    "from torchvision import models\n",
    "import timm\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy\n",
    "import random\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, LambdaLR, ExponentialLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcda54-5505-422e-a835-442c23d01d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(2024)\n",
    "np.random.seed(2024)\n",
    "torch.manual_seed(2024)\n",
    "torch.cuda.manual_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f10b2c-123f-4382-8140-1bcdc03a5242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load ResNet model\n",
    "model = models.resnet50(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8886452-99e0-4ed7-9c2c-965bd7d404fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features \n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs,6), nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a877e-92d8-41b1-b538-c75d389e5452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from timm.models import create_model\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters()) # Calculate the number of model parameters\n",
    "print(f\"Number of parameters in resnet50 model: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f30d78b-495d-466d-b596-db7d9205f99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preprocessing and augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resize the image\n",
    "    transforms.ToTensor(), # Convert image to PyTorch tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863ddd8-f023-4870-a05f-5469cfb41f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/MULTI_TUMOR_split\" # Root directory for data storage\n",
    "# Define train, validation datasets\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "val_data = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=transform)\n",
    "batch_size=64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=64)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b1b14-fdaa-4836-8e64-823df30081f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot training/validation metrics and ROC curve\n",
    "def plot_train_curve(modal ,train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr):\n",
    "    # Parameters: train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr\n",
    "    \n",
    "     # --- Plot Accuracy curve ---\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_history, label=\"Train Acc\")\n",
    "    plt.plot(val_acc_history, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Acc_curve_of_' + modal + '.png') # Save Accuracy curve\n",
    "    plt.close()\n",
    "\n",
    "    # --- Plot AUC curve ---\n",
    "    plt.figure()\n",
    "    plt.plot(val_auc_history, label=\"Val AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Auc_curve_of_' + modal + '.png') # Save AUC curve\n",
    "    plt.close()\n",
    "\n",
    "    # --- Plot F1 curve ---\n",
    "    plt.figure()\n",
    "    plt.plot(val_f1_history, label=\"Val F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'F1_curve_of_' + modal + '.png') # Save F1 curve\n",
    "    plt.close()\n",
    "\n",
    "    # --- Plot Recall curve ---\n",
    "    plt.figure()\n",
    "    plt.plot(val_r_history, label=\"Val Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.savefig('./inde_train_curve_images/' + 'Recall_curve_of_' + modal + '.png') # Save Recall curve\n",
    "    plt.close()\n",
    "    \n",
    "    # --- Plot ROC curve ---\n",
    "    plt.figure()\n",
    "    plt.plot(val_fpr, val_tpr, label=f'ROC curve (area = {val_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('./inde_train_curve_images/' + 'ROC_curve_of_' + modal + '.png') # Save ROC curve\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5dc64-39f2-4330-acff-ea5e731456fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings for transfer learning layers\n",
    "flair_model = copy.deepcopy(model)\n",
    "flair_model.to(device)\n",
    "flair_params_to_update = [] # Parameters to update\n",
    "all_layer_names = [name for name, _ in model.named_parameters()] # All parameter names in the model\n",
    "free_layer_names = all_layer_names[-20:] # The last 20 parameter names of the model, you can change the number of the layers you want to finetune\n",
    "# Only update layers listed in free_layer_names\n",
    "for name, param in flair_model.named_parameters():\n",
    "    if name not in free_layer_names:\n",
    "        param.requires_grad = False \n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "        flair_params_to_update.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6a5a9-4f1e-4a77-9dd7-643d6e368eba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "alpha = torch.tensor([3.0, 1.0])\n",
    "optimizer = optim.Adam(flair_params_to_update, lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a80558-9ca4-49e0-bc1a-c47aa0941edc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and validation\n",
    "num_epochs = 500\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "val_auc_history = []\n",
    "val_f1_history = []\n",
    "val_r_history = []\n",
    "\n",
    "min_loss = float('inf') # Initialize min_loss to infinity\n",
    "best_acc = 0.0\n",
    "best_auc = 0.0\n",
    "patience = 30\n",
    "early_stop = patience\n",
    "change_rate = 15 # Change learning rate after this many epochs if performance doesn't improve\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    flair_model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = flair_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    lr = optimizer.param_groups[0]['lr'] # Learning rate for the current epoch\n",
    "    # Decay learning rate if early stop counter is below patience - change_rate\n",
    "    if early_stop < (patience - change_rate):\n",
    "        lr -= lr / (change_rate + early_stop)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print ('Decay learning rate to lr: {}.'.format(lr))\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    train_acc_history.append(train_acc)\n",
    "    \n",
    "    # Validation\n",
    "    flair_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_outputs_list = []\n",
    "    val_labels_list = []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = flair_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_outputs_list.append(outputs.cpu().numpy())\n",
    "            val_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        val_outputs = np.concatenate(val_outputs_list, axis=0)\n",
    "        val_labels = np.concatenate(val_labels_list, axis=0)\n",
    "\n",
    "        val_fpr, val_tpr, _ = roc_curve(val_labels, val_outputs[:, 1], pos_label=1) # Calculate AUC\n",
    "        val_auc = auc(val_fpr, val_tpr)\n",
    "        val_auc_history.append(val_auc)\n",
    "\n",
    "        val_f1 = f1_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "        val_f1_history.append(val_f1)\n",
    "\n",
    "        val_r = recall_score(val_labels, np.argmax(val_outputs, axis=1),average='weighted')\n",
    "        val_r_history.append(val_r)\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "        # Early stopping logic\n",
    "        if best_acc < val_acc: # Save best model based on highest accuracy\n",
    "            best_acc = val_acc\n",
    "            early_stop = patience\n",
    "            model_name = 'flair_model_fml.pth' # Set model save filename\n",
    "            torch.save(flair_model.state_dict(), model_name)\n",
    "        else: \n",
    "            early_stop -= 1\n",
    "        # Stop training when early_stop counter reaches 0\n",
    "        if early_stop == 0:\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}, Val Recall: {val_r:.4f}, Val Loss: {avg_val_loss:.4f}, Early Stop: {early_stop:.0f}\")\n",
    "\n",
    "plot_train_curve('flair', train_acc_history, val_acc_history, val_auc_history, val_f1_history, val_r_history, val_fpr, val_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1612d-705e-4ad9-98c9-05117f40a86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flair_model.load_state_dict(torch.load(\"flair_model_fml.pth\")) # Load the best model saved during the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33d92fc8-aba1-49a6-a606-7b58da2659cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, recall_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170edb83-063b-48a9-aaa2-5691cce34362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a data loader for the test images\n",
    "import torch.nn.functional as F\n",
    "data_dir = \"/root/autodl-tmp/project/MedSAM-0.1/data/MULTI_TUMOR_split/test\"\n",
    "image_data = datasets.ImageFolder(data_dir, transform=transform)\n",
    "data_loader = DataLoader(image_data, batch_size=1, shuffle=False)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = flair_model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.append(labels.item())\n",
    "        y_pred.append(predicted.item())\n",
    "        y_scores.append(probabilities.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_scores = np.concatenate(y_scores, axis=0)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred,average='weighted')\n",
    "recall = recall_score(y_true, y_pred,average='weighted')\n",
    "print(f\"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a380bc6-472c-4550-96e1-d5c9959b143b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9406f-1473-480b-9e14-8ada00383ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Define class labels\n",
    "labels = ['Glioma','Meningioma', 'Neurocitoma', 'NORMAL', 'Outros', 'Schwannoma']  # Replace with your actual class labels...\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\".0f\", cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
